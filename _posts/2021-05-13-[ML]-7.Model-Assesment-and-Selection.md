---
title: '[ML] 7.Model Assesment and Selection'
use_math: true
comments: true
layout: single
classes: wide
categories:

  - 머신러닝
  - ESL

tags:
  
  - 머신러닝
  - ESL
---





이 단원에서는 모형 성능 평가와, 평가를 바탕으로 모형을 선택하는 방법에 대해 다룰 것이다. 

## 2. Bias, Variance and Model Complexity

input vector $X$ target variable $Y$ 그리고 train data로부터 추정된 $\hat{f}(X)$ 예측모델이 있다고 하자. **Loss function**은 실제 $Y$값과 모델로부터 예측한 $\hat{f}(X)$ 사이의 error를 나타낸다. Loss function $L(Y,\hat{f}(X))$ 을 계산하는 방법은 여러가지가 있는데 일반적으로 절대값의 차이나 차이의 제곱을 이용한다. 


$$
L(Y, \hat{f}(X))=\left\{\begin{array}{ll}
(Y-\hat{f}(X))^{2} & \text { squared error } \\
|Y-\hat{f}(X)| & \text { absolute error }
\end{array}\right.
$$


여기서 **Test error(Generalization error)**는 독립적인 test sample에 대한 prediction error다.  train sample $\mathcal{T}$ 은 주어진 상태이며, test error는 특정한 training set에 대한 error를 나타낸다


$$
\operatorname{Err}_{\mathcal{T}}=\mathrm{E}[L(Y, \hat{f}(X)) \mid \mathcal{T}]
$$


이번에는 train set이 고정된 것이 아니라 random하게 주어진 상황에서 기대값을 구해보자. 이를 **expected test error** 혹은 **expected prediction error**라 하며 다음과 같이 구할 수 있다. 


$$
\operatorname{Err}=\mathrm{E}[L(Y, \hat{f}(X))]=\mathrm{E}\left[\operatorname{Err}_{\mathcal{T}}\right]
$$


![7](http://whdbfla6.github.io/assets/ml/7.1.PNG)



이 그림에서 연한 red 커브는 100개 train set 각각에 대한 $Err_{\mathcal{T}}$ 을 나타낸다. 진한 red 커브는 100개의 $Err_{\mathcal{T}}$ 에 대한 기대값으로 expected prediction error다. 우리의 목표는 train set이 주어졌을 때 error에 대한 기대값을 구하는 것이지만 대부분의 방법론은 error의 기대값을 추정하고 있다. 

모델의 구조가 복잡해지는 경우 bias는 감소하지만 variance가 커지는 문제가 생긴다. 즉 새로운 데이터가 들어왔을 때 예측을 잘 못하는 것을 의미한다. bias와 variance를 모두 줄여 expected test error를 최소화하는 모델을 선택하는 것이 중요하다

**training error**는 모든 train sample에 대해 loss값을 계산해 평균을 구한 것이다


$$
\overline{\mathrm{err}}=\frac{1}{N} \sum_{i=1}^{N} L\left(y_{i}, \hat{f}\left(x_{i}\right)\right) .
$$


train error의 경우 모델의 구조가 복잡해질수록 작은 값을 가져 모델의 복잡도가 충분히 크다면(ex.데이터를 모두 연결한 function) 0의 값을 갖는다. 따라서 training error는 test error에 대한 추정치로 사용할 수 없다. 일반적으로는 데이터를 ```training set, validation set, test set```으로 분리해 training set은 모델을 fitting하는 경우 validation set은 모델 선택을 위해 prediction error를 추정하는 경우, test set은 최종적으로 선택한 모델에 대한 prediction error를 구하는데 사용된다. 여기서 모형 선택은 서로 다른 모형의 성능을 추정해 가장 좋은 성능을 가진 모형을 고르는 과정이며, 모형 평가는 모형을 선택한 후에 새로운 데이터에 대한 Generalization error를 추정하는 것을 의미한다.  일반적으로 전체 데이터 셋의 반을 training set 나머지의 1/2을 각각 validation set과 test set으로 사용한다. 하지만 대부분의 상황에서는 데이터의 양이 충분하지 않아 세 개의 파트로 나눌 수가 없다. 따라서 이후의 단원에서는 이러한 상황에서 모델 성능을 평가하는 방법에 대해 다룰 것이다. 



## 3. The Bias-Variance Decomposition

$Y=f(X)+\epsilon\quad \text{where}\quad E(\epsilon)=0\ Var(\epsilon)=\sigma^2$  모형을 가정한다고 하자. 특정 포인트  $X=x_0$ 에 대한 회귀식 $\hat{f}(X)$의 expected prediction error를 구하면 다음과 같다.


$$
\begin{aligned}
\operatorname{Err}\left(x_{0}\right) &=E\left[\left(Y-\hat{f}\left(x_{0}\right)\right)^{2} \mid X=x_{0}\right] \\
&=\sigma_{\varepsilon}^{2}+\left[\mathrm{E} \hat{f}\left(x_{0}\right)-f\left(x_{0}\right)\right]^{2}+E\left[\hat{f}\left(x_{0}\right)-\mathrm{E} \hat{f}\left(x_{0}\right)\right]^{2} \\
&=\sigma_{\varepsilon}^{2}+\operatorname{Bias}^{2}\left(\hat{f}\left(x_{0}\right)\right)+\operatorname{Var}\left(\hat{f}\left(x_{0}\right)\right)
\end{aligned}
$$


첫번째 term은 얼마나 $f(X_0)$를 잘 예측했든지에 상관없이 줄일 수 없는 error다. 두번째 term은 bias를 제곱한 부분으로 추정치의 평균값과 true mean의 차이를 나타낸다. 마지막 부분은 variance로 $\hat{f}(x_0)$가 그 평균값을 기준으로 얼마만큼의 폭으로 변동하는 지를 나타낸다. 앞서 설명했듯이 모형의 복잡도가 커질수록 bias는 줄어들지만 variance가 커진다.



> EX1 . KNN

K-nearest-neighbor regression fit의 경우에 squared error loss는 다음과 같다. 식에서 k가 커지는 경우 bias는 커지고 분산이 커지는 것을 확인할 수 있다.


$$
\begin{aligned}
\operatorname{Err}\left(x_{0}\right) &=E\left[\left(Y-\hat{f}_{k}\left(x_{0}\right)\right)^{2} \mid X=x_{0}\right] \\
&=\sigma_{\varepsilon}^{2}+\left[f\left(x_{0}\right)-\frac{1}{k} \sum_{\ell=1}^{k} f\left(x_{(\ell)}\right)\right]^{2} + \frac{1}{k^2}k\sigma^2_{\epsilon} \\&=\sigma_{\varepsilon}^{2}+\left[f\left(x_{0}\right)-\frac{1}{k} \sum_{\ell=1}^{k} f\left(x_{(\ell)}\right)\right]^{2} + \frac{1}{k}\sigma^2_{\epsilon}
\end{aligned}
$$


> EX2. Linear Model

p개의 components로 구성된 파라미터 벡터를 $\beta$라고 할 때 linear model $\hat{f}_p(x)=x^T\beta$의 squared error loss는 다음과 같다.


$$
\begin{aligned}
\operatorname{Err}\left(x_{0}\right) &=E\left[\left(Y-\hat{f}_{k}\left(x_{0}\right)\right)^{2} \mid X=x_{0}\right] \\ &=\sigma_{\varepsilon}^{2}+\left[f\left(x_{0}\right)-\mathrm{E} \hat{f}_{p}\left(x_{0}\right)\right]^{2}+\left\|\mathbf{h}\left(x_{0}\right)\right\|^{2} \sigma_{\varepsilon}^{2}
\end{aligned}\\
\text{where}\quad \mathbf{h}\left(x_{0}\right)=\mathbf{X}\left(\mathbf{X}^{T} \mathbf{X}\right)^{-1} x_{0}
$$


회귀 추정식 $\hat{f}_{p}\left(x_{0}\right)=x_{0}^{T}\left(\mathbf{X}^{T} \mathbf{X}\right)^{-1} \mathbf{X}^{T} \mathbf{y}$ 에 대해 분산값을 구하면  $x_0^T(X^TX)^{-1}X^TX(X^TX)^{-1}x_0\sigma_{\epsilon}^2$로 정리하면, $x_0^T(X^TX)^{-1}x_0\sigma_{\epsilon}^2$이다. 분산은 각 포인트 $x_0$에 따라 다른 값을 가지며 평균값을 구하면 $\frac{p}{N}\sigma_{\epsilon}^2$ 이다. 


$$
\begin{aligned}
\frac{1}{N}\sum_{i=1}^Nx_i^T(X^TX)^{-1}x_i\sigma_{\epsilon}^2&=\sigma_{\epsilon}^2\frac{1}{N}\sum_{i=1}^Nx_i^T(X^TX)^{-1}x_i\\ &= \frac{1}{N}tr(X(X^TX)^{-1}X^T)\sigma_{\epsilon}^2\\ &= \frac{1}{N}tr(I_p)\sigma_{\epsilon}^2 \\ &= \frac{p}{N}\sigma_{\epsilon}^2
\end{aligned}
$$


따라서 모든 $x_i$에 대해 squared error를 구해 평균값을 구하면 다음과 같으며 이를 **in-sample error**라 한다. 여기서 모델의 복잡도가 p에 따라 결정되는 것을 확인할 수 있다. 


$$
\frac{1}{N} \sum_{i=1}^{N} \operatorname{Err}\left(x_{i}\right)=\sigma_{\varepsilon}^{2}+\frac{1}{N} \sum_{i=1}^{N}\left[f\left(x_{i}\right)-\mathrm{E} \hat{f}\left(x_{i}\right)\right]^{2}+\frac{p}{N} \sigma_{\varepsilon}^{2}
$$


ridge regression의 경우 모델의 bias를 best fitting linear model에서 발생하는 bias와 나머지 부분의 합으로 나타낼 수 있다.  

($E(f(X)-X^T\beta)^2$ 을 최소화 하는 $\beta$를  $\beta_{*}$라고 할 때, $\beta{*}$ 는 best fitting 회귀식의 베타 추정치다)


$$
\begin{aligned}
\mathrm{E}_{x_{0}}\left[f\left(x_{0}\right)-\mathrm{E} \hat{f}_{\alpha}\left(x_{0}\right)\right]^{2} &=\mathrm{E}_{x_{0}}\left[f\left(x_{0}\right)-x_{0}^{T} \beta_{*} + x_{0}^{T} \beta_{*} -\mathrm{E} x_{0}^{T} \hat{\beta}_{\alpha} \right]^{2} \\ &=\mathrm{E}_{x_{0}}\left[f\left(x_{0}\right)-x_{0}^{T} \beta_{*}\right]^{2}+\mathrm{E}_{x_{0}}\left[x_{0}^{T} \beta_{*}-\mathrm{E} x_{0}^{T} \hat{\beta}_{\alpha}\right]^{2} \\
&\left.=\text { Ave[Model Bias }]^{2}+\text { Ave[Estimation Bias }\right]^{2}
\end{aligned}
$$


- 첫번째 term(Average squared model bias): best fitting 회귀식의 추정치와 true function 사이의 error
- 두번째 term(Average squared estimation bias): $E(x_0^T\hat{\beta}_a)$와 best fitting 회귀식 추정치 사이의 error

일반적인 회귀식의 경우 estimation bias가 0인 반면 ridge나 lasso와 같은 제약 term을 포함한 회귀식은 양의 값을 갖는다. 하지만 bias-variance trade-off 관계에 따라 variance가 감소한다는 장점이 있다. 



## 4. Optimism of the Training Error Rate



