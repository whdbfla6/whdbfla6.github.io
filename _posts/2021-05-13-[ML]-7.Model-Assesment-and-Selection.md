---
title: '[ML] 7.Model Assesment and Selection'
use_math: true
comments: true
layout: single
classes: wide
categories:

  - 머신러닝
  - ESL

tags:
  
  - 머신러닝
  - ESL
---





이 단원에서는 모형 성능 평가와, 평가를 바탕으로 모형을 선택하는 방법에 대해 다룰 것이다. 

## 2. Bias, Variance and Model Complexity

input vector $X$ target variable $Y$ 그리고 train data로부터 추정된 $\hat{f}(X)$ 예측모델이 있다고 하자. **Loss function**은 실제 $Y$값과 모델로부터 예측한 $\hat{f}(X)$ 사이의 error를 나타낸다. Loss function $L(Y,\hat{f}(X))$ 을 계산하는 방법은 여러가지가 있는데 일반적으로 절대값의 차이나 차이의 제곱을 이용한다. 


$$
L(Y, \hat{f}(X))=\left\{\begin{array}{ll}
(Y-\hat{f}(X))^{2} & \text { squared error } \\
|Y-\hat{f}(X)| & \text { absolute error }
\end{array}\right.
$$


여기서 **Test error(Generalization error)**는 독립적인 test sample에 대한 prediction error다.  train sample $\mathcal{T}$ 은 주어진 상태이며, test error는 특정한 training set에 대한 error를 나타낸다


$$
\operatorname{Err}_{\mathcal{T}}=\mathrm{E}[L(Y, \hat{f}(X)) \mid \mathcal{T}]
$$


이번에는 train set이 고정된 것이 아니라 random하게 주어진 상황에서 기대값을 구해보자. 이를 **expected test error** 혹은 **expected prediction error**라 하며 다음과 같이 구할 수 있다. 


$$
\operatorname{Err}=\mathrm{E}[L(Y, \hat{f}(X))]=\mathrm{E}\left[\operatorname{Err}_{\mathcal{T}}\right]
$$



![7](http://whdbfla6.github.io/assets/ml/7.1.PNG)



이 그림에서 연한 red 커브는 100개 train set 각각에 대한 $Err_{\mathcal{T}}$ 을 나타낸다. 진한 red 커브는 100개의 $Err_{\mathcal{T}}$ 에 대한 기대값으로 expected prediction error다. 우리의 목표는 train set이 주어졌을 때 error에 대한 기대값을 구하는 것이지만 대부분의 방법론은 error의 기대값을 추정하고 있다. 

모델의 구조가 복잡해지는 경우 bias는 감소하지만 variance가 커지는 문제가 생긴다. 즉 새로운 데이터가 들어왔을 때 예측을 잘 못하는 것을 의미한다. bias와 variance를 모두 줄여 expected test error를 최소화하는 모델을 선택하는 것이 중요하다.

**training error**는 모든 train sample에 대해 loss값을 계산해 평균을 구한 것이다

$$
\overline{\mathrm{err}}=\frac{1}{N} \sum_{i=1}^{N} L\left(y_{i}, \hat{f}\left(x_{i}\right)\right) .
$$


train error의 경우 모델의 구조가 복잡해질수록 작은 값을 가져 모델의 복잡도가 충분히 크다면(ex.데이터를 모두 연결한 function) 0의 값을 갖는다. 따라서 training error는 test error에 대한 추정치로 사용할 수 없다. 일반적으로는 데이터를 ```training set, validation set, test set```으로 분리해 training set은 모델을 fitting하는 경우 validation set은 모델 선택을 위해 prediction error를 추정하는 경우, test set은 최종적으로 선택한 모델에 대한 prediction error를 구하는데 사용된다. 여기서 모형 선택은 서로 다른 모형의 성능을 추정해 가장 좋은 성능을 가진 모형을 고르는 과정이며, 모형 평가는 모형을 선택한 후에 새로운 데이터에 대한 Generalization error를 추정하는 것을 의미한다.  일반적으로 전체 데이터 셋의 반을 training set 나머지의 1/2을 각각 validation set과 test set으로 사용한다. 하지만 대부분의 상황에서는 데이터의 양이 충분하지 않아 세 개의 파트로 나눌 수가 없다. 따라서 이후의 단원에서는 이러한 상황에서 모델 성능을 평가하는 방법에 대해 다룰 것이다. 



## 3. The Bias-Variance Decomposition

$Y=f(X)+\epsilon\quad \text{where}\quad E(\epsilon)=0\ Var(\epsilon)=\sigma^2$  모형을 가정한다고 하자. 특정 포인트  $X=x_0$ 에 대한 회귀식 $\hat{f}(X)$의 expected prediction error를 구하면 다음과 같다.


$$
\begin{aligned}
\operatorname{Err}\left(x_{0}\right) &=E\left[\left(Y-\hat{f}\left(x_{0}\right)\right)^{2} \mid X=x_{0}\right] \\
&=\sigma_{\varepsilon}^{2}+\left[\mathrm{E} \hat{f}\left(x_{0}\right)-f\left(x_{0}\right)\right]^{2}+E\left[\hat{f}\left(x_{0}\right)-\mathrm{E} \hat{f}\left(x_{0}\right)\right]^{2} \\
&=\sigma_{\varepsilon}^{2}+\operatorname{Bias}^{2}\left(\hat{f}\left(x_{0}\right)\right)+\operatorname{Var}\left(\hat{f}\left(x_{0}\right)\right)
\end{aligned}
$$


첫번째 term은 얼마나 $f(X_0)$를 잘 예측했든지에 상관없이 줄일 수 없는 error다. 두번째 term은 bias를 제곱한 부분으로 추정치의 평균값과 true mean의 차이를 나타낸다. 마지막 부분은 variance로 $\hat{f}(x_0)$가 그 평균값을 기준으로 얼마만큼의 폭으로 변동하는 지를 나타낸다. 앞서 설명했듯이 모형의 복잡도가 커질수록 bias는 줄어들지만 variance가 커진다.



> EX1 . KNN

K-nearest-neighbor regression fit의 경우에 squared error loss는 다음과 같다. 식에서 k가 커지는 경우 bias는 커지고 분산이 커지는 것을 확인할 수 있다.


$$
\begin{aligned}
\operatorname{Err}\left(x_{0}\right) &=E\left[\left(Y-\hat{f}_{k}\left(x_{0}\right)\right)^{2} \mid X=x_{0}\right] \\
&=\sigma_{\varepsilon}^{2}+\left[f\left(x_{0}\right)-\frac{1}{k} \sum_{\ell=1}^{k} f\left(x_{(\ell)}\right)\right]^{2} + \frac{1}{k^2}k\sigma^2_{\epsilon} \\&=\sigma_{\varepsilon}^{2}+\left[f\left(x_{0}\right)-\frac{1}{k} \sum_{\ell=1}^{k} f\left(x_{(\ell)}\right)\right]^{2} + \frac{1}{k}\sigma^2_{\epsilon}
\end{aligned}
$$


> EX2. Linear Model

p개의 components로 구성된 파라미터 벡터를 $\beta$라고 할 때 linear model $\hat{f}_p(x)=x^T\beta$의 squared error loss는 다음과 같다.


$$
\begin{aligned}
\operatorname{Err}\left(x_{0}\right) &=E\left[\left(Y-\hat{f}_{k}\left(x_{0}\right)\right)^{2} \mid X=x_{0}\right] \\ &=\sigma_{\varepsilon}^{2}+\left[f\left(x_{0}\right)-\mathrm{E} \hat{f}_{p}\left(x_{0}\right)\right]^{2}+\left\|\mathbf{h}\left(x_{0}\right)\right\|^{2} \sigma_{\varepsilon}^{2}
\end{aligned}\\
\text{where}\quad \mathbf{h}\left(x_{0}\right)=\mathbf{X}\left(\mathbf{X}^{T} \mathbf{X}\right)^{-1} x_{0}
$$


회귀 추정식 에 대해 분산값을 구하면  $x_0^T(X^TX)^{-1}X^TX(X^TX)^{-1}x_0\sigma_{\epsilon}^2$ 로 정리하면, $x_0^T(X^TX)^{-1}x_0\sigma_{\epsilon}^2$이다. 분산은 각 포인트 $x_0$에 따라 다른 값을 가지며 평균값을 구하면 $\frac{p}{N}\sigma_{\epsilon}^2$ 이다. 


$$
\begin{aligned}
\frac{1}{N}\sum_{i=1}^Nx_i^T(X^TX)^{-1}x_i\sigma_{\epsilon}^2&=\sigma_{\epsilon}^2\frac{1}{N}\sum_{i=1}^Nx_i^T(X^TX)^{-1}x_i\\ &= \frac{1}{N}tr(X(X^TX)^{-1}X^T)\sigma_{\epsilon}^2\\ &= \frac{1}{N}tr(I_p)\sigma_{\epsilon}^2 \\ &= \frac{p}{N}\sigma_{\epsilon}^2
\end{aligned}
$$

> ridge regression bias


ridge regression의 경우 모델의 bias를 best fitting linear model에서 발생하는 bias와 나머지 부분의 합으로 나타낼 수 있다.  

($E(f(X)-X^T\beta)^2$ 을 최소화 하는 $\beta$를  $\beta_{\ast}$라고 할 때 $\beta_{\ast}$ 는 best fitting 회귀식의 베타 추정치다)


$$
\begin{aligned}
\mathrm{E}_{x_{0}}\left[f\left(x_{0}\right)-\mathrm{E} \hat{f}_{\alpha}\left(x_{0}\right)\right]^{2} &=\mathrm{E}_{x_{0}}\left[f\left(x_{0}\right)-x_{0}^{T} \beta_{*} + x_{0}^{T} \beta_{*} -\mathrm{E} x_{0}^{T} \hat{\beta}_{\alpha} \right]^{2} \\ &=\mathrm{E}_{x_{0}}\left[f\left(x_{0}\right)-x_{0}^{T} \beta_{*}\right]^{2}+\mathrm{E}_{x_{0}}\left[x_{0}^{T} \beta_{*}-\mathrm{E} x_{0}^{T} \hat{\beta}_{\alpha}\right]^{2} \\
&\left.=\text { Ave[Model Bias }]^{2}+\text { Ave[Estimation Bias }\right]^{2}
\end{aligned}
$$


- 첫번째 term(Average squared model bias): best fitting 회귀식의 추정치와 true function 사이의 error
- 두번째 term(Average squared estimation bias): $E(x_0^T\hat{\beta}_a)$와 best fitting 회귀식 추정치 사이의 error

일반적인 회귀식의 경우 estimation bias가 0인 반면 ridge나 lasso와 같은 제약 term을 포함한 회귀식은 양의 값을 갖는다. 하지만 bias-variance trade-off 관계에 따라 variance가 감소한다는 장점이 있다. 



## 4. Optimism of the Training Error Rate

training set $\mathcal{T}=\{(x_1,y_1),(x_2,y_2),\cdots,(x_n,y_n)\}$ 이 주어졌을 때 모형 $\hat{f}$ 에 대한 **generalization error**는 $Err_{\mathcal{T}} = E_{X_0,Y_0}[L(Y_0,\hat{f}(X_0))\mid\mathcal{T}]$ 이다. Training set은 고정된 상태이며 $(X_0,Y_0)$는 새로운 데이터 포인트다. 모든 training set에 대해 generalizaiton error를 구해 기대값을 취하면 expected error를 얻을 수 있으며 형태는 다음과 같다.  


$$
E_{\mathcal{T}}E_{X_0,Y_0}[L(Y_0,\hat{f}(X_0))\mid\mathcal{T}]
$$


일반적으로 training error $\frac{1}{N} \sum_{i=1}^{N} L\left(y_{i}, \hat{f}\left(x_{i}\right)\right)$ 는 모형을 만들 때 사용한 데이터를 가지고 error를 구한 것이기 때문에 true error $Err_{\mathcal{T}}$ 보다 작다. 따라서 training error가 $Err_{\mathcal{T}}$ 의 optimistic estimate으로 볼 수 있다. 



> In-sample error


$$
\operatorname{Err}_{\mathrm{in}}=\frac{1}{N} \sum_{i=1}^{N} \mathrm{E}_{Y^{0}}\left[L\left(Y_{i}^{0}, \hat{f}\left(x_{i}\right)\right) \mid \mathcal{T}\right]
$$



In-sample error는 train error의 과소추정된 정도 $op$를 더해준 통계량이다. $Y_i^0$는 각 training point $x_i\ i=1,2,\cdots,n$ 에서의 new response N개를 의미한다. 각  $x_i\ (i=1,\cdots,N)$에서의 new response N개와 $\hat{f(x_i)}$의 expected loss를 구해 평균을 취하면 in-sample error를 구할 수 있다

$op$는 in-sample error와 $Err_{in}$의 차이로 정의된다. 일반적으로 training error는 downward biased 되어 있기 때문에 $op$는 양수다. training set을 random variable로 보고 $\mathcal{T}$ 에 대해 expectation을 취하면 average optimism $\omega$ 을 얻을 수 있다. 우리의 관심사는 $op$ 를 추정하는 것이지만 일반적으로 $\omega$를 추정하는 것이 더 쉽다


$$
op = Err_{in}-\overline{err}\quad \omega = E_y(op)
$$


> sqaured error, 0-1 loss function

sqaured error, 0-1 loss function 을 사용하는 경우에 $\omega$를 다음과 같이 쉽게 구할 수 있다. 


$$
\omega = \frac{2}{N}\sum_{i=1}^N Cov(\hat{y}_i,y_i)
$$

<details>
<summary>증명</summary>
<div markdown="1">   

증명내용

</div>
</details>



## 10. Cross- validation

모델링의 최종 목적은 관찰하지 않은 데이터 즉 test data에 대한 error를 줄이는 것이다. 하지만 대부분의 경우에서 test data를 구할 수 없어 이미 가지고 있는 데이터를 활용해 test MSE를 예측해야 한다. 이미 보유한 데이터를 나눠 그 일부를 test data 와 유사하게 사용하는 것이다. 대표적인 방법 중 하나가 cross valdiation이다. 

### 10-1 K-fold CV

데이터가 충분한 경우에 데이터를 train set과 validation set으로 나눠 예측 모형의 성능을 평가하는데 사용할 수 있다. 일반적으로는 데이터가 충분하지 않기 때문에 **k-fold cv** 를 사용한다. 데이터를 K개의 영역으로 나눠서 K-1개의 데이터 셋은 모델을 fitting하는데 나머지 한개의 데이터 셋은 test하는데 사용한다. K=5인 경우를 도식화하면 다음과 같다. 



![7](http://whdbfla6.github.io/assets/ml/7.2.PNG)



데이터를 5개의 영역으로 나누고 4개의 영역에 속한 데이터로 모델을 fitting하고 나머지 영역의 데이터로 prediction error를 계산한다. 이를 모든 데이터 section에 대해 반복하면 5개의 추정치를 얻을 수 있으며, 평균을 내면 prediction error에 대한 추정치를 얻을 수 있다.

일반화시킨 cross validation estimate of prediction error는 다음과 같다. 일반적으로 k값은 5나 10을 사용한다. 


$$
\mathrm{CV}(\hat{f})=\frac{1}{N} \sum_{i=1}^{N} L\left(y_{i}, \hat{f}^{-\kappa(i)}\left(x_{i}\right)\right)
$$


다음으로 K값에 따른 추정치의 bias-variance trade off 관계를 살펴볼 것이다

> K=2



- 데이터의 반만 사용해서 모델을 피팅했기 때문에 validation MSE가 큰 값을 가질 수 밖에 없다. 즉 TEST MSE를 과대추정해 bias가 커진다
- bias가 커지는 대신에 variance는 작아진다



> K=N LOOCV



- train data의 대부분을 사용했기 때문에 unbiased하다(training MSE는 test MSE의 unbiased estimator다)
- N-1개의 training set은 유사하기 때문에 N개의 모형들은 서로 높은 correlation을 가져 variance가 커진다
- 수식적으로 이해하면 분산을 구하는데 MSE의 공분산 값이 포함되기 때문에 Correlation이 커지면 분산이 커진다


$$
\begin{aligned}Var(CV(k)) &= VAR(\dfrac{1}{k} MSE_1 + \dfrac{1}{k} MSE_2 + ... + \dfrac{1}{k} MSE_K)\\ &= \dfrac{1}{k^2}[VAR(MSE_1) + VAR(MSE_2) + ... + VAR(MSE_K)+ ... + \sum^{}_{i=/=j} COV(MSE_i,MSE_J)] 
\end{aligned}
$$


- 모델 fitting을 N번 반복해야 하기 때문에 N이 커지는 경우에 fitting하는데 시간이 오래 걸린다

- OLS 회귀 분석의 경우 아래의 식을 통해 한번에 CV 추정치를 얻을 수 있다. 


$$
CV(n) = \dfrac{1}{N} \sum^{N}_{i=1} (\frac{y_i-\hat{y_i}}{1-{h_ii}})^2
$$


<details>
<summary>증명</summary>
<div markdown="1">     

증명내용

</div>
</details>

## 11. Bootstrap Methods

부트스트랩은 가지고 있는 데이터에서 복원 추출을 하여 여러개의 샘플을 만드는 방법론이다. training set $Z = (z_1,z_2,\cdots,z_N)\quad where\ z_i=(x_i,y_i)$ 가 있다고 하자. 기본적인 아이디어는 training set에서 중복을 허용해 N개의 데이터를 추출하고, 이를 $B$번 반복해서 $B$개의 부트스트랩 데이터셋을 얻는 것이다. 

부트스트랩 데이터셋은 prediction error을 추정하는데 어떻게 사용될까? b번째 부트스트랩 데이터셋에서 $\hat{f}^{\star b}$ 를 구하고 original dataset을 사용해 $x_i$에 대한 loss를 계산하면 $\widehat{Err}_{boot}$을 구할 수 있다. 


$$
\widehat{\operatorname{Err}}_{\text {boot }}=\frac{1}{B} \frac{1}{N} \sum_{b=1}^{B} \sum_{i=1}^{N} L\left(y_{i}, \hat{f}^{* b}\left(x_{i}\right)\right)
$$


하지만 $\widehat{Err}_{boot}$ 의 경우 training sample과 test sample의 역할을 하고 있는 original dataset에 중복되는 값이 많아 예측값이 좋은 방향으로 나오는 경우가 많다. 즉 오버피팅 되는 것이다. 이를 방지하기 위해 제안된 추정치는 $\widehat{Err}^{(1)}$로, $x_i$에 대한 loss를 계산할 때 $B$개의 $\hat{f}^{\star b}$ 를 모두 사용하지 않고  $x_i$를 포함하고 있지 않은 부트스트랩 데이터셋만 사용한다. 


$$
\widehat{\mathrm{Err}}^{(1)}=\frac{1}{N} \sum_{i=1}^{N} \frac{1}{\left|C^{-i}\right|} \sum_{b \in C^{-i}} L\left(y_{i}, \hat{f}^{* b}\left(x_{i}\right)\right)
$$


이 때 부트스트랩 샘플 b에 특정 i관측치가 포함되지 않을 확률은 대략 0.368로 train data의 사이즈가 절반으로 줄게된다. 즉 true error보다 ubward biased될 가능성이 높은 것이다. 


$$
\begin{aligned}
\operatorname{Pr}\{\text { observation } i \in \text { bootstrap sample } b\} &=1-\left(1-\frac{1}{N}\right)^{N} \\
& \approx 1-e^{-1} \\
&=0.632 .
\end{aligned}
$$


".632 estimator"는 $\widehat{Err}^{(1)}$ 추정치를 training error 방향으로 감소시킴으로써 upward bias를 줄여주게 된다. 


$$
\widehat{\mathrm{Err}}^{(.632)}=.368 \cdot \overline{\mathrm{err}}+.632 \cdot \widehat{\mathrm{Err}}^{(1)}
$$
