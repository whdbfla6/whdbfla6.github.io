---
title: '[FCB] 6. MCMC Diagnostics'
use_math: true
comments: true
layout: single
classes: wide
categories:

  - 베이지안
  - FCB

tags:
  
  - 베이지안
  - FCB
---



## MCMC Diagnostics

Monte Carlo나 Markov chain Monte Carlo 근사는 다음을 만족하는 sequence $\{\phi^{(1)}, \ldots, \phi^{(S)}\}$를 얻는 것이 주 목적이다 


$$
\frac{1}{S} \sum_{s=1}^{S} g\left(\phi^{(s)}\right) \approx \int g(\phi) p(\phi) d \phi
$$


즉 target probability $p(\phi)$ 분포(일반적으로 베이즈 통계에서는 사후분포를 말한다)를 따르는 $g(\phi)$ 의 기대값이 $\{g(\phi^{(1)}), \ldots, g(\phi^{(S)})\}$ 의 평균과 동일한 값을 갖기를 바라는 것이다. 이를 만족하기 위해서 $\{\phi^{(1)}, \ldots, \phi^{(S)}\}$ 의 empirical distribution이 target distribution $p(\phi)$ 과 유사해야 한다. Monte Carlo나 Markov chain Monte Carlo 근사는 이러한 sequence를 얻는 대표적인 방법론이다. 

다음 예시를 통해 MC와 MCMC의 차이가 무엇인지 살펴보자. 우리의 Target distribution이 $\delta$와 $\theta$의 joint distribution이라고 하자. $\delta$는 $\delta \in \{ 1,2,3\}$ discrete variable 이며, $\theta \in R$ 는 continuous variable이다. $p(\delta),\ p(\theta\mid\delta)$는 다음과 같다.


$$
\{\operatorname{Pr}(\delta=1), \operatorname{Pr}(\delta=2), \operatorname{Pr}(\delta=3)\}=(0.45,0.1,0.45)\\ p(\theta \mid \delta)=\operatorname{dnorm}\left(\theta, \mu_{\delta}, \sigma_{\delta}\right)\\ \left(\mu_{1}, \mu_{2}, \mu_{3}\right)=(-3,0,3),\left(\sigma_{1}, \sigma_{2}, \sigma_{3}\right)=(1 / 3,1 / 3,1 / 3)
$$


이는 3개의 정규분포에 대한 mixture model로 $\theta$의 exact한 marginal density 는 다음과 같이 구할 수 있다. 


$$
p(\theta) = \sum p(\theta\mid\delta)p(\delta)
$$
 

> Monte Carlo

1. $\delta$의 marginal distribution에서 $\delta$를 샘플링한다
2. 그 값을  $p(\theta\mid\delta)$에 넣어 $\theta$를 샘플링한다
3. 샘플링 된 $(\delta,\theta)$ pair는 joint distribution $p(\delta,\theta)$ 에 대한 샘플로 볼 수 있다

이 과정을 통해 얻은 empirical distribution은 다음과 같다. 실제 분포에 잘 근사했음을 확인할 수 있다. 



![7](http://whdbfla6.github.io/assets/fcb/6.1.PNG)



> Gibbs sampler

깁스 샘플러의 경우 $\theta$와 $\delta$의 full conditional distribution으로 부터 joint distribution을 구한다. $\theta$에 대한 full conditional distribution은 주어진 상태이며, 베이즈 정리를 이용해 $\delta$의 full conditional distribution을 구해보려고 한다


$$
\operatorname{Pr}(\delta=d \mid \theta)=\frac{\operatorname{Pr}(\delta=d) \times \operatorname{dnorm}\left(\theta, \mu_{d}, \sigma_{d}\right)}{\sum_{d=1}^{3} \operatorname{Pr}(\delta=d) \times \operatorname{dnorm}\left(\theta, \mu_{d}, \sigma_{d}\right)}, \text { for } d \in\{1,2,3\}
$$


아래 그림은 gibbs sampler로부터 구한 1000개 샘플의 히스토그램이다. $-3$ 부근에서 데이터가 부족하고 $0$과 $3$근처에서 샘플링이 많이 된 것을 확인할 수 있다. 이는 $\theta$의 값이 특정 영역에서 stuck되었음을 의미하는데, 이러한 stickiness를 autocorrelation이 높다고 표현한다. chain에서 연속적인 값 사이에 correlation이 높은 것이다. 



![7](http://whdbfla6.github.io/assets/fcb/6.2.PNG)



샘플링의 과정을 sequence $\{\phi^{(1)}, \ldots, \phi^{(S)}\}$ 가 파라미터 공간을 돌아다니는 과정이라고 볼 때 $A$라는 set에 머무르는 시간은 $\int_A P(\phi)$에 비례한다. 즉 확률분포의 면적에 비례하는 것이다. 파라미터 공간의 disjoint subset $A_1,A_2,A_3$가 있을 때 $P(A_2)<P(A_1)\approx P(A_3)$라고 하자. Integral approximation 관점에서 $A_2$공간에 적게 머물고 $A_1$과 $A_3$ 공간에서 많은 시간동안 머무르길 바랄 것이다. Markov chain의 initial point가 $A_2$공간에 있을 때 반복횟수 $S$를 늘린다면, 다음과 같은 상황에 놓일 것이다.

1. $A_2$공간에서 나와 확률이 높은 공간으로 이동
2. $A_1$ 과 $A_3$ 사이를 이동

첫번째 상태를 Chain이 stationarity를 달성했다 혹은 수렴했다고 표현할 수 있다. Markov chain이 높은 확률을 갖는 파라미터 공간에서 시작했다면, 수렴을 달성하는 것은 어려운 일이 아니다. 하지만 어떤 공간에서 initial point를 시작해야하는지는 알 수 없다. 또한 autocorrelation이 높은 체인은 수렴하는데까지 오랜 시간이 걸린다는 문제가 있다. 

두번째 상태는 particle이 얼마나 빠르게 파라미터 공간을 움직이는 지와 관련이 있다. speed of mixing이라 불린다. autocorrelation이 0인 경우에 서로다른 파라미터 공간을 넘나들기 쉽다. autocorrelation이 높은 경우는 서로 다른 파라미터 공간으로 넘어가기까지 오랜 시간이 걸린다. 

지금까지 살펴보았을 때  mcmc 샘플이 사후분포에 근사하는지의 여부는 autocorrelation과 크게 연관이 있다. 

