---
title: '[FCB] 6. MCMC Diagnostics'
use_math: true
comments: true
layout: single
classes: wide
categories:

  - 베이지안
  - FCB

tags:
  
  - 베이지안
  - FCB
---



## MCMC Diagnostics

Monte Carlo나 Markov chain Monte Carlo 근사는 다음을 만족하는 sequence $\{\phi^{(1)}, \ldots, \phi^{(S)}\}$를 얻는 것이 주 목적이다 


$$
\frac{1}{S} \sum_{s=1}^{S} g\left(\phi^{(s)}\right) \approx \int g(\phi) p(\phi) d \phi
$$


즉 target probability $p(\phi)$ 분포(일반적으로 베이즈 통계에서는 사후분포를 말한다)를 따르는 $g(\phi)$ 의 기대값이 $\{g(\phi^{(1)}), \ldots, g(\phi^{(S)})\}$ 의 평균과 동일한 값을 갖기를 바라는 것이다. 이를 만족하기 위해서 $\{\phi^{(1)}, \ldots, \phi^{(S)}\}$ 의 empirical distribution이 target distribution $p(\phi)$ 과 유사해야 한다. Monte Carlo나 Markov chain Monte Carlo 근사는 이러한 sequence를 얻는 대표적인 방법론이다. 

다음 예시를 통해 MC와 MCMC의 차이가 무엇인지 살펴보자. 우리의 Target distribution이 $\delta$와 $\theta$의 joint distribution이라고 하자. $\delta$는 $\delta \in \{ 1,2,3\}$ discrete variable 이며, $\theta \in R$ 는 continuous variable이다. $p(\delta),\ p(\theta\mid\delta)$는 다음과 같다.


$$
\{\operatorname{Pr}(\delta=1), \operatorname{Pr}(\delta=2), \operatorname{Pr}(\delta=3)\}=(0.45,0.1,0.45)\\ p(\theta \mid \delta)=\operatorname{dnorm}\left(\theta, \mu_{\delta}, \sigma_{\delta}\right)\\ \left(\mu_{1}, \mu_{2}, \mu_{3}\right)=(-3,0,3),\left(\sigma_{1}, \sigma_{2}, \sigma_{3}\right)=(1 / 3,1 / 3,1 / 3)
$$


이는 3개의 정규분포에 대한 mixture model로 $\theta$의 exact한 marginal density 는 다음과 같이 구할 수 있다. 


$$
p(\theta) = \sum p(\theta\mid\delta)p(\delta)
$$
 

> Monte Carlo

1. $\delta$의 marginal distribution에서 $\delta$를 샘플링한다
2. 그 값을  $p(\theta\mid\delta)$에 넣어 $\theta$를 샘플링한다
3. 샘플링 된 $(\delta,\theta)$ pair는 joint distribution $p(\delta,\theta)$ 에 대한 샘플로 볼 수 있다

이 과정을 통해 얻은 empirical distribution은 다음과 같다. 실제 분포에 잘 근사했음을 확인할 수 있다. 



![7](http://whdbfla6.github.io/assets/fcb/6.1.PNG)



> Gibbs sampler

깁스 샘플러의 경우 $\theta$와 $\delta$의 full conditional distribution으로 부터 joint distribution을 구한다. $\theta$에 대한 full conditional distribution은 주어진 상태이며, 베이즈 정리를 이용해 $\delta$의 full conditional distribution을 구해보려고 한다


$$
\operatorname{Pr}(\delta=d \mid \theta)=\frac{\operatorname{Pr}(\delta=d) \times \operatorname{dnorm}\left(\theta, \mu_{d}, \sigma_{d}\right)}{\sum_{d=1}^{3} \operatorname{Pr}(\delta=d) \times \operatorname{dnorm}\left(\theta, \mu_{d}, \sigma_{d}\right)}, \text { for } d \in\{1,2,3\}
$$


아래 그림은 gibbs sampler로부터 구한 1000개 샘플의 히스토그램이다. $-3$ 부근에서 데이터가 부족하고 $0$과 $3$근처에서 샘플링이 많이 된 것을 확인할 수 있다. 이는 $\theta$의 값이 특정 영역에서 stuck되었음을 의미하는데, 이러한 stickiness를 autocorrelation이 높다고 표현한다. chain에서 연속적인 값 사이에 correlation이 높은 것이다. 



![7](http://whdbfla6.github.io/assets/fcb/6.2.PNG)



샘플링의 과정을 sequence $\{\phi^{(1)}, \ldots, \phi^{(S)}\}$ 가 파라미터 공간을 돌아다니는 과정이라고 볼 때 $A$라는 set에 머무르는 시간은 $\int_A P(\phi)$에 비례한다. 즉 확률분포의 면적에 비례하는 것이다. 파라미터 공간의 disjoint subset $A_1,A_2,A_3$가 있을 때 $P(A_2)<P(A_1)\approx P(A_3)$라고 하자. Integral approximation 관점에서 $A_2$공간에 적게 머물고 $A_1$과 $A_3$ 공간에서 많은 시간동안 머무르길 바랄 것이다. Markov chain의 initial point가 $A_2$공간에 있을 때 반복횟수 $S$를 늘린다면, 다음과 같은 상황에 놓일 것이다.

1. $A_2$공간에서 나와 확률이 높은 공간으로 이동
2. $A_1$ 과 $A_3$ 사이를 이동

첫번째 상태를 Chain이 stationarity를 달성했다 혹은 수렴했다고 표현할 수 있다. Markov chain이 높은 확률을 갖는 파라미터 공간에서 시작했다면, 수렴을 달성하는 것은 어려운 일이 아니다. 하지만 어떤 공간에서 initial point를 시작해야하는지는 알 수 없다. 또한 autocorrelation이 높은 체인은 수렴하는데까지 오랜 시간이 걸린다는 문제가 있다. 

두번째 상태는 particle이 얼마나 빠르게 파라미터 공간을 움직이는 지와 관련이 있다. speed of mixing이라 불린다. autocorrelation이 0인 경우에 서로다른 파라미터 공간을 넘나들기 쉽다. autocorrelation이 높은 경우는 서로 다른 파라미터 공간으로 넘어가기까지 오랜 시간이 걸린다. 





> autocorrelation

지금까지 살펴보았을 때  mcmc 샘플이 사후분포에 근사하는지의 여부는 autocorrelation과 크게 연관이 있었다. autocorrelation은 sequence $\{\phi^{(1)}, \ldots, \phi^{(S)}\}$ 가 주어졌을 때 $\phi^{(s)}$와 t시점 이후인 $\phi^{(s+t)}$ 사이의 correlation을 의미한다. 
$$
\operatorname{acf}_{t}(\phi)=\frac{\frac{1}{S-t} \sum_{s=1}^{S-t}\left(\phi_{s}-\bar{\phi}\right)\left(\phi_{s+t}-\bar{\phi}\right)}{\frac{1}{S-1} \sum_{s=1}^{S}\left(\phi_{s}-\bar{\phi}\right)^{2}}
$$
시간 간의 차이 lag이 커질수록 auto-correlation은 감소하며 독립인 샘플을 얻기 위해서는 k번째 떨어진 데이터만을 사용하는 thinning을 적용하면 된다. 



> Brooks Gelman-Rubin statistic(BGR)

BGR은 MCMC샘플이 잘 수렴했는지 볼 수 있는 지표 중 하나로 체인 간의 분산과 체인 내의 분산으로 구성된다. 구하는 과정은 다음과 같다

1. M개의 체인에 대해 2xN번의 iteration을 진행한다
2. 처음 N개 샘플을 버린다
3. within chain variance 와 between chain variance를 구한다

$$
W=\frac{1}{M} \sum_{j=1}^{M} s_{j}^{2},\quad B=\frac{N}{M-1} \sum_{j=1}^{M}\left(\bar{\theta}_{j}-\bar{\theta}\right)^{2}
$$

4. $\operatorname{var}(\theta)=\left(1-\frac{1}{N}\right) W+\frac{1}{N} B$ 을 계산한다

$B$의 경우 chain 간의 initial point가 달라서 생기는 분산까지 고려되기 때문에 $var(\theta)$는 overestimate 되는 경향이 있다. 하지만 unbiased estimator다. 

5. potential scale reduction factor $\hat{R}$을 계산해서 1보다 큰 경우 Iteration 반복을 통해 1에 가깝게 만들어야 한다. 1에 가까운 것은 수렴이 어느정도 달성되었음을 의미한다

$$
\hat{R}=\frac{\sqrt{\hat{var}(\theta)}}{W}
$$

