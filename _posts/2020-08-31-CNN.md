--- 
layout: single
title: CNN(Convolution Neural Network)
use_math: true
commtents: true

---

## 0. Introduction
![cnn](http://whdbfla6.github.io/assets/images/cnn8.png)

**convolution neural network**는 말 그대로 **convolution** 연산이 들어가는 뉴럴 네트워크를 의미한다. CNN은 고양이가 이미지를 볼 때 바라보는 위치에 따라서 자극받는 뇌의 부분이 다르다는 점을 착안해 만들어졌다고 한다. CNN은 convolution연산 외에도 중간중간 RELU와 max-pooling을 적용하며, 마지막에는 FC(Fully Connected Layer)을 통과하여 labeling을 하게 된다.

**convolution, max-pooling, FC**가 무엇인지 하나하나 알아보자



## 1. Convolution? 


![CNN1.jpg](http://whdbfla6.github.io/assets/images/cnn1.JPG)


**Convolution**은 이미지 위에서 stride만큼 filter를 이동시키면서 겹쳐지는 부분의 각 원소의 값을 곱해서 더한 값을 출력으로 하는 연산이다. 이 과정을 통해서 이미지의 특성을 추출해내는 것이다


![CNN](http://whdbfla6.github.io/assets/images/gif1.gif)


### 1-1 이미지
![CNN2.jpg](http://whdbfla6.github.io/assets/images/cnn2.JPG)

input data인 이미지는 다음과 같은 요소로 구성된다:  **batch_size, channel, height, width**

**채널의 수**는 흑백인지 컬러인지에 따라서 달라지는데 흑백 이미지의 경우 채널 1개로 구성되며, 컬러 이미지는 R G B 빨강 초록 파랑 3개의 채널로 구성된다. 위의 초록 그림이 3장 겹쳐있다고 생각하면 된다. 그렇다면 Input data에 적힌 각각의 숫자는 무엇을 의미할까? 이는 이미지를 구성하는 최소단위인 **픽셀**의 값으로, 이미지를 이루는 점이라고 생각하면 된다. 픽셀은 이미지의 밝기와 컬러를 나타내며 픽셀들이 모여 하나의 이미지를 만들어낸다. height와 width의 곱은 이미지가 총 몇개의 픽셀로 구성되어 있는지 나타내준다

### 1-2 필터

필터는 다음과 같은 요소로 구성된다: **in_channels, out_channels, kernel_size, stride, padding**

#### 1) in_channels, out_channels, kernel_size

Input data가 3x28x28로 3개의 채널로 구성되어있다고 하자. 이에 따라 필터 또한 3개의 channel로 구성되어야 하며, **in_channels**의 값은 3이다. **kernel_size**는 필터의 가로/세로 길이를 나타내는데, 필터가 3x5x5 사이즈로 구성되어 있으면 kernel_size는 5다
![CNN5.jpg](http://whdbfla6.github.io/assets/images/cnn5.JPG)

구체적인 연산과정은 아래와 같다. 이미지의 각 채널과 filter의 연산과정으로 3개의 결과물이 출력되며 이 결과물들의 각 원소별 덧셈 과정을 통해 최종적인 결과물이 산출된다. 즉 채널의 수와 상관없이 **하나의 feature map**이 만들어진다는 것이다

![cnn](https://taewanmerepo.github.io/2018/01/cnn/conv2.jpg)

**out_channel**은 몇 종류의 필터를 사용되는지에 따라 결정된다. 채널의 수와 상관없이 하나의 필터를 사용할 때 하나의 feature map이 만들어지며, 4종류의 필터를 사용한다면 총 4개의 feature map이 만들어질 것이다. 이 때 out_channel 값이 4다


지금까지의 말을 정리하면, input size: 3x28x28 , filter size: 3x5x5, 4종류의 필터 사용 : **in_channel=3, out_channel=4 kernel_size=5**

#### 2) stride

**stride**는 필터를 이동시킬 때 몇칸 씩 이동하는지를 나타내는 숫자다. 아래는 필터가 한칸씩 이동하고 있기 때문에 Sride는 1이다

![SegmentLocal](http://whdbfla6.github.io/assets/images/gif1.gif)

#### 3) padding

**padding**은 input data인 이미지 외각에 특정 값으로 채워주는 것을 의미하며, 일반적으로 0으로 채워주기 때문에 zero-padding이라 한다. padding은 convolution 연산 이후에 정보가 손실되는 것을 막기 위해 사용하는 것인데, 자세히 알아보자.

![CNN7.jpg](http://whdbfla6.github.io/assets/images/cnn7.JPG)


convolution 연산 이후에 나오는 **output size**를 구하는 공식은 다음과 같다: $((inputsize) - (filtersize))  /  (Stride) + 1 $

input_size가 7 filter_size가 3일 때 공식에 대입을 하면,

Stride가 1일 때 $(7 - 3)  /  1 +1 = 5$,  5x5사이즈<br/>Stride가 2일 때 $(7 - 3)  /  2 +1 = 3$,  3x3사이즈가 output size다

결과를 살펴보면 7x7사이즈였던 이미지가 연산을 진행함에 따라 사이즈가 줄어드는 것을 확인할 수 있고, 이는 기존의 정보를 잃어버리는 결과를 가져온다.<br/>이를 방지하기 위해 사용하는 것이 **zero padding**이다. 기존 이미지에 zero padding을 하게되면 7x7사이즈가 9x9가 된다. 이에 stride 1 filter_size=3으로 연산을 진행하면 $(9 - 3)  /  1 +1 = 7$로 이미지 사이즈가 보존되는 것을 확인할 수 있다. 

일반적으로 output size를 구하기 위해 다음 공식을 사용한다. $((inputsize) + (padding*2) - (filtersize))  /  (Stride) + 1 $


## 2. Max-Pooling(=Sampling) & FC

![CNN9.jpg](http://whdbfla6.github.io/assets/images/cnn9.JPG)

**max-pooling**은 일반적으로 convolution 연산 이후에 진행이 되는데, size가 2라고 하면 각각의 2x2 사이즈에서 가장 큰 값을 출력하는 과정이다. 이는 가장 큰 값이 이미지의 특징을 대표한다는 점을 기반으로 하고 있다. Max pooling은 왜 하는 걸까? convolution 연산 output을 그대로 사용하게 되면 수많은 feature가 만들어지고 이는 **오버피팅**의 문제를 가져온다. Max-pooling은 기존의 이미지 사이즈를 반으로 줄여(Size 2 기준) 오버피팅을 방지해주며 더 나아가 연산 과정을 줄여준다

convolution 연산, Relu 그리고 Max-pooling을 반복적으로 진행해 최종적으로 3x3x10사이즈가 output으로 나오게 되면, 이 300개의 값을 input으로 받아서 FC를 통과하게된다. 마지막엔 Softmax 함수를 지나 원하는 label을 얻을 수 있다



참고자료:<br/> 
[모두를 위한 딥러닝 시즌1](https://hunkim.github.io/ml/)<br/>[모두를 위한 딥러닝 시즌2](https://deeplearningzerotoall.github.io/season2/)<br/>[Learn Again!](https://twlab.tistory.com/23)<br/>[TAEWAN.KIM 블로그](http://taewan.kim/post/cnn/)<br/> [towardsdatascience](https://towardsdatascience.com/introduction-to-convolutional-neural-network-cnn-de73f69c5b83)
