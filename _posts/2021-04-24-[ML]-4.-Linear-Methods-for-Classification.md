---
title: '[ML] 4. Linear Methods for Classification'
use_math: true
comments: true
layout: single
classes: wide
categories:

  - 머신러닝
  - ESL

---

Linear Regression of an Indicator matrix

## 2. Linear Regression of an Indicator Matrix

여기서는 분류를 위해 각 response variable을 **Indicator variable**로 둔다. K번째 클래스에 해당하는 반응변수는 k번째 성분은 1 나머지는 0인 $1\times K$ 길이의 벡터다.  N개의 데이터를 모두 포함한 Indicator response matrix $Y$는 $N \times K$ 크기의 행렬로, 0과 1의 값만 갖는다. p개의 coefficients들이 있다고 할 때, $X$ 는 상수 term 1을 포함한 $N\times (p+1)$ 크기의 행렬이 되며, linear regression에 fitting한 결과 $\hat{Y}$ 은 다음과 같이 구할 수 있다. 


$$
Y = \begin{bmatrix}{} 0 \\ \vdots \\1 \\ \vdots \\0 \end{bmatrix}= \begin{bmatrix}{} Y_1 \\ \vdots \\Y_k \\ \vdots \\Y_K \end{bmatrix}\quad X: N \times (p+1)\ matrix\quad \hat{B} = (X^TX)^{-1}X^TY\quad \hat{Y} = X\hat{B}=X(X^TX)^{-1}X^TY
$$


새로운 관측지 $x$ 에 대한 $\hat{f(x)}$ 추정치는 $(1,x^T)\hat{B}$  로 길이가 K인 벡터이며, k번째 원소가 가장 큰$ 값을 가질 때 k번째 클래스로 분류가 된다. 


$$
\hat{f(x)} = (1,x^T)\hat{B}\quad \hat{G}(x)=argmax_{k\in G}\hat{f}(x)
$$



$Y_k$ 에 대해 $E(Y_K|X=x)=P(G=k|X=x)$ 이기 때문에 각 추정치는 X값이 주어질 때 k 클래스에 속할 확률을 의미한다. 여기서 각 추정치는 확률에 대한 좋은 추정치일까? 확률값이 되기 위해서는 각 추정치는 0과 1사이의 값을 가져야하고, 모든 추정치의 합이 1이어야 한다. 



> $\sum{\hat{f}_k(x)} = 1$


$$
\begin{bmatrix} \sum{\hat{f}(x)} \\ \vdots \\ \sum{\hat{f}(x)} \end{bmatrix} = \begin{bmatrix} \hat{Y}_{11} & \cdots & \hat{Y}_{1n} \\ \vdots & & \vdots \\ \hat{Y}_{n1} & \cdots & \hat{Y}_{nn} \end{bmatrix} \begin{bmatrix} 1 \\ \vdots \\ 1\end{bmatrix} = X(X^TX)X^TY\mathbf{1_n} = H\mathbf{1_n} =\mathbf{1_n}
$$


여기서 $X(X^TX)X^TY$ 는 projection matrix로 $X(X^TX)X^TY\mathbf{1_n}$ 은  $\mathbf{1_n}$ 을 X의 column space에 projection하는 것을 의미한다.  여기서 $X$ intercept term인 $\mathbf{1_n}$ 을 이미 포함하고 있기 때문에 projection한 결과도 $\mathbf{1_n}$ 이다. 추정치의 합이 1이라는 것에 대한 증명이 끝났다



> $0 \le \hat{f}(X) \le 1$

linear regression의 특성상 train data의 바깥 범위에 대한 추정치는 음수 혹은 1보다 큰 값을 가질 수 있어 확률의 속성을 위반하게 된다. 이 경우에 basis expansion을 통해 확률에 대한 consistent한 추정치를 얻을 수 있는데, 이후에 배울 로지스틱 회귀가 대표적인 예다.



회귀식 접근방식의 또다른 문제점은 class가 3개 이상 존재하는 경우에 특정 클래스가 다른 클래스에 가려져 완벽하게 분류가 되지 않는다는 점이다. 

p=2이고 클래스가 3개인 다음 예시를 살펴보자.

![4.1](http://whdbfla6.github.io/assets/ml/4.1.png)

이 경우 클래스 2에 대한 회귀식은 수평선 형태를 갖기 때문에 모든 데이터는 클래스1 혹은 클래스3으로 분류가 된다. 이번에는 linear한 형태가 아닌 quadratic term을 추가해서 fitting을 해보자.

![4.1](http://whdbfla6.github.io/assets/ml/4.2.PNG)

2차항을 포함해 fitting한 결과 클래스 2 또한 분류가 잘되고 있음을 확인할 수 있다. 

## 3. Linear Discriminant Analysis



### 3.2 Computations for LDA



### 3.3 Reduced Rank Linear Discriminant Analysis 



## 4. Logistic Regression



### 4.3 Quadratic Approximations and Inferences 



## 5. Separating Hyperplanes



